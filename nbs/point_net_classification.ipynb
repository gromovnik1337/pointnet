{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oe8-0UxArBog"
   },
   "source": [
    "# **PointNet**\n",
    "This is an implementation of PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cOWmLLmovGG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7fYK1merYKQ"
   },
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoH1KIXi9VTX"
   },
   "source": [
    "# **Get the dataset (if required)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebWmXmiJrdNg",
    "outputId": "25c722af-6fff-4387-eab8-c069a08a4d37"
   },
   "outputs": [],
   "source": [
    "# Download the ModelNet10 dataset directly to the runtime. It comprises 10 categories, 3,991 models for training and 908 for testing.\n",
    "#!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QmNwakirtnc"
   },
   "outputs": [],
   "source": [
    "#!unzip -q ModelNet10.zip;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5YLkSkpr4_w"
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path(\"ModelNet10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siqYQGbjsWS3",
    "outputId": "3f9b6876-dbbc-41d7-880a-033533f6e05f"
   },
   "outputs": [],
   "source": [
    "# Create a dict with class names & their indices.\n",
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so-R9dvN9jNb"
   },
   "source": [
    "# **Read & visualize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQagmVVhtdWB"
   },
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "  \"\"\"Reads .off mesh files.\n",
    "  \"\"\"\n",
    "  if 'OFF' != file.readline().strip():\n",
    "    raise('Not a valid OFF header')\n",
    "  n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "  verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "  faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "  return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZbLBx4suFXX",
    "outputId": "360d1949-ccd0-4691-e713-4e292764b48c"
   },
   "outputs": [],
   "source": [
    "# Test the dataset reading.\n",
    "with open(path/\"bed/train/bed_0001.off\", 'r') as f:\n",
    "  verts, faces = read_off(f)\n",
    "i,j,k = np.array(faces).T\n",
    "x,y,z = np.array(verts).T\n",
    "\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2cX3DDtueBa"
   },
   "outputs": [],
   "source": [
    "def visualize_rotate(data):\n",
    "  \"\"\"Visulize mesh data with automatic rotation play button.\n",
    "  \"\"\"\n",
    "  x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "  frames=[]\n",
    "\n",
    "  def rotate_z(x, y, z, theta):\n",
    "    w = x+1j*y\n",
    "    return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "  for t in np.arange(0, 10.26, 0.1):\n",
    "    xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "    frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
    "  \n",
    "  fig = go.Figure(data=data, \n",
    "                  layout=go.Layout(\n",
    "                    updatemenus=[dict(type='buttons',\n",
    "                                      showactive=False,\n",
    "                                      y=1,\n",
    "                                      x=0.8,\n",
    "                                      xanchor='left',\n",
    "                                      yanchor='bottom',\n",
    "                                      pad=dict(t=45, r=10),\n",
    "                                      buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
    "                                                                    transition=dict(duration=0),\n",
    "                                                                                    fromcurrent=True,\n",
    "                                                                                    mode='immediate'\n",
    "                                                                    )]\n",
    "                                                    )\n",
    "                                              ]\n",
    "                                    )\n",
    "                                ]\n",
    "                                ),\n",
    "                  frames=frames\n",
    "                  )\n",
    "\n",
    "  return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "K66SlHyPvn0l",
    "outputId": "08a9d10b-6969-46e6-c3a2-ba396c550a0e"
   },
   "outputs": [],
   "source": [
    "visualize_rotate([go.Mesh3d(x=x, y=y, z=z, color='lightpink', opacity=0.50, i=i,j=j,k=k)]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "7n70invKvyWi",
    "outputId": "b3b27f54-544f-43a5-863c-75b546d4ff27"
   },
   "outputs": [],
   "source": [
    "# Although the mesh looks like the bed, the vertices of the mesh do not!\n",
    "# This is a very critical lesson about shape information coming from different data types!\n",
    "visualize_rotate([go.Scatter3d(x=x, y=y, z=z,\n",
    "                                   mode='markers')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sH-_GLGwFxR"
   },
   "outputs": [],
   "source": [
    "def pcshow(xs,ys,zs):\n",
    "  \"\"\"Visualize x, y, z point clouds.\n",
    "  \"\"\"\n",
    "  data=[go.Scatter3d(x=xs, y=ys, z=zs,\n",
    "                                  mode='markers')]\n",
    "  fig = visualize_rotate(data)\n",
    "  fig.update_traces(marker=dict(size=2,\n",
    "                    line=dict(width=2,\n",
    "                    color='DarkSlateGrey')),\n",
    "                    selector=dict(mode='markers'))\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "msplNBtFwj8h",
    "outputId": "c84eb690-bb3b-465a-c2d5-2756870863cc"
   },
   "outputs": [],
   "source": [
    "pcshow(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19o2vxDO9sYO"
   },
   "source": [
    "# **Add extra points on the pointcloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g02RiQfMwxIh"
   },
   "outputs": [],
   "source": [
    "# Sample points on the surfaces of the mesh:\n",
    "class PointSampler(object):\n",
    "  def __init__(self, output_size):\n",
    "      assert isinstance(output_size, int)\n",
    "      self.output_size = output_size\n",
    "  \n",
    "  def triangle_area(self, pt1, pt2, pt3):\n",
    "      side_a = np.linalg.norm(pt1 - pt2)\n",
    "      side_b = np.linalg.norm(pt2 - pt3)\n",
    "      side_c = np.linalg.norm(pt3 - pt1)\n",
    "      s = 0.5 * ( side_a + side_b + side_c)\n",
    "      return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "  def sample_point(self, pt1, pt2, pt3):\n",
    "      # barycentric coordinates on a triangle\n",
    "      # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "      s, t = sorted([random.random(), random.random()])\n",
    "      f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "      return (f(0), f(1), f(2))\n",
    "      \n",
    "  \n",
    "  def __call__(self, mesh):\n",
    "      verts, faces = mesh\n",
    "      verts = np.array(verts)\n",
    "      areas = np.zeros((len(faces)))\n",
    "\n",
    "      for i in range(len(areas)):\n",
    "          areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                          verts[faces[i][1]],\n",
    "                                          verts[faces[i][2]]))\n",
    "          \n",
    "      sampled_faces = (random.choices(faces, \n",
    "                                    weights=areas,\n",
    "                                    cum_weights=None,\n",
    "                                    k=self.output_size))\n",
    "      \n",
    "      sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "      for i in range(len(sampled_faces)):\n",
    "          sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                  verts[sampled_faces[i][1]],\n",
    "                                                  verts[sampled_faces[i][2]]))\n",
    "      \n",
    "      return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "jcxAeoBd7m5F",
    "outputId": "e28eede0-8048-4ef8-d932-95a1ad3f8738"
   },
   "outputs": [],
   "source": [
    "pointcloud = PointSampler(3000)((verts, faces))\n",
    "pcshow(*pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C6b_XL09yt8"
   },
   "source": [
    "# **Normalize & Augment the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMKmB9su7-4x"
   },
   "outputs": [],
   "source": [
    "# Normalize the point cloud:\n",
    "class Normalize(object):\n",
    "  def __call__(self, pointcloud):\n",
    "      assert len(pointcloud.shape)==2\n",
    "      \n",
    "      norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "      norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "      return  norm_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "rGWFuU-O9BoN",
    "outputId": "541a14d9-775d-42f3-bf85-ad0679e8c9cd"
   },
   "outputs": [],
   "source": [
    "norm_pointcloud = Normalize()(pointcloud)\n",
    "pcshow(*norm_pointcloud.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hclz6zqo91p_"
   },
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "  def __call__(self, pointcloud):\n",
    "      assert len(pointcloud.shape)==2\n",
    "\n",
    "      theta = random.random() * 2. * math.pi\n",
    "      rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                              [ math.sin(theta),  math.cos(theta),    0],\n",
    "                              [0,                             0,      1]])\n",
    "      \n",
    "      rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "      return  rot_pointcloud\n",
    "    \n",
    "class RandomNoise(object):\n",
    "  def __call__(self, pointcloud):\n",
    "      assert len(pointcloud.shape)==2\n",
    "\n",
    "      noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "  \n",
    "      noisy_pointcloud = pointcloud + noise\n",
    "      return  noisy_pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "CFIh0iKQ975N",
    "outputId": "dec65c36-8dae-4345-d5ab-acb0f5903ba4"
   },
   "outputs": [],
   "source": [
    "rot_pointcloud = RandRotation_z()(norm_pointcloud)\n",
    "noisy_rot_pointcloud = RandomNoise()(rot_pointcloud)\n",
    "pcshow(*noisy_rot_pointcloud.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-IBa1pN-_xs"
   },
   "source": [
    "# **Create Torch dataset**\n",
    "https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuRgdmTb_5rj"
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "  def __call__(self, pointcloud):\n",
    "      assert len(pointcloud.shape)==2\n",
    "\n",
    "      return torch.from_numpy(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4bDkn5dE35B",
    "outputId": "f1ed1224-33f6-4058-b2f2-3c481de43934"
   },
   "outputs": [],
   "source": [
    "print(ToTensor()(noisy_rot_pointcloud)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6UONHEQFABX",
    "outputId": "5d709c3d-c63f-4e60-c0a8-55f2a5993eb2"
   },
   "outputs": [],
   "source": [
    "ToTensor()(noisy_rot_pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEVfFBokFa5I"
   },
   "outputs": [],
   "source": [
    "# Default transforms, if there is no need for data augmentation.\n",
    "def default_transforms():\n",
    "  return transforms.Compose([\n",
    "                              PointSampler(1024),\n",
    "                              Normalize(),\n",
    "                              ToTensor()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jwnUqz-FeYz"
   },
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "  def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "      self.root_dir = root_dir\n",
    "      folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "      self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "      self.transforms = transform if not valid else default_transforms()\n",
    "      self.valid = valid\n",
    "      self.files = []\n",
    "      for category in self.classes.keys():\n",
    "          new_dir = root_dir/pathlib.Path(category)/folder\n",
    "          for file in os.listdir(new_dir):\n",
    "              if file.endswith('.off'):\n",
    "                  sample = {}\n",
    "                  sample['pcd_path'] = new_dir/file\n",
    "                  sample['category'] = category\n",
    "                  self.files.append(sample)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.files)\n",
    "\n",
    "  def __preproc__(self, file):\n",
    "      verts, faces = read_off(file)\n",
    "      if self.transforms:\n",
    "          pointcloud = self.transforms((verts, faces))\n",
    "      return pointcloud\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "      pcd_path = self.files[idx]['pcd_path']\n",
    "      category = self.files[idx]['category']\n",
    "      with open(pcd_path, 'r') as f:\n",
    "          pointcloud = self.__preproc__(f)\n",
    "      return {'pointcloud': pointcloud, \n",
    "              'category': self.classes[category]}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4XRsaeFGKCQ"
   },
   "outputs": [],
   "source": [
    "# 1024 points per cloud as in the paper!\n",
    "train_transforms = transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize(),\n",
    "                    RandRotation_z(),\n",
    "                    RandomNoise(),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DysJHO8GQ_h"
   },
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(path, transform=train_transforms)\n",
    "valid_ds = PointCloudData(path, valid=True, folder='test', transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnbRJFE9GUUu",
    "outputId": "1a93b0c4-76cb-44b9-b58c-22941d15b919"
   },
   "outputs": [],
   "source": [
    "inv_classes = {i: cat for cat, i in train_ds.classes.items()};\n",
    "inv_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUI9CNzQGuUy",
    "outputId": "39e81fa1-a9eb-447f-f975-c4f8309a9363"
   },
   "outputs": [],
   "source": [
    "print('Train dataset size: ', len(train_ds))\n",
    "print('Valid dataset size: ', len(valid_ds))\n",
    "print('Number of classes: ', len(train_ds.classes))\n",
    "print('Sample pointcloud shape: ', train_ds[0]['pointcloud'].size())\n",
    "print('Sample class: ', inv_classes[train_ds[0]['category']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QurRkbmlG5A-"
   },
   "source": [
    "# **Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDT01_GcHEWI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "  def __init__(self, k=3):\n",
    "    super().__init__()\n",
    "    self.k=k\n",
    "    self.conv1 = nn.Conv1d(k,64,1)\n",
    "    self.conv2 = nn.Conv1d(64,128,1)\n",
    "    self.conv3 = nn.Conv1d(128,1024,1)\n",
    "    self.fc1 = nn.Linear(1024,512)\n",
    "    self.fc2 = nn.Linear(512,256)\n",
    "    self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "    self.bn1 = nn.BatchNorm1d(64)\n",
    "    self.bn2 = nn.BatchNorm1d(128)\n",
    "    self.bn3 = nn.BatchNorm1d(1024)\n",
    "    self.bn4 = nn.BatchNorm1d(512)\n",
    "    self.bn5 = nn.BatchNorm1d(256)\n",
    "      \n",
    "\n",
    "  def forward(self, input):\n",
    "    # input.shape == (bs,n,3)\n",
    "    bs = input.size(0)\n",
    "    xb = F.relu(self.bn1(self.conv1(input)))\n",
    "    xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "    xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "    pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "    flat = nn.Flatten(1)(pool)\n",
    "    xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "    xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "    \n",
    "    #initialize as identity\n",
    "    init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "    if xb.is_cuda:\n",
    "      init=init.cuda()\n",
    "    matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "  def __init__(self):\n",
    "      super().__init__()\n",
    "      self.input_transform = Tnet(k=3)\n",
    "      self.feature_transform = Tnet(k=64)\n",
    "      self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      \n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      \n",
    "  def forward(self, input):\n",
    "      matrix3x3 = self.input_transform(input)\n",
    "      # batch matrix multiplication\n",
    "      xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "      xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "      matrix64x64 = self.feature_transform(xb)\n",
    "      xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = self.bn3(self.conv3(xb))\n",
    "      xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      output = nn.Flatten(1)(xb)\n",
    "      return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "  def __init__(self, classes = 10):\n",
    "      super().__init__()\n",
    "      self.transform = Transform()\n",
    "      self.fc1 = nn.Linear(1024, 512)\n",
    "      self.fc2 = nn.Linear(512, 256)\n",
    "      self.fc3 = nn.Linear(256, classes)\n",
    "      \n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(512)\n",
    "      self.bn2 = nn.BatchNorm1d(256)\n",
    "      self.dropout = nn.Dropout(p=0.3)\n",
    "      self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, input):\n",
    "      xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "      xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "      xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "      output = self.fc3(xb)\n",
    "      return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcAfmrVqJZ_I"
   },
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
    "    criterion = torch.nn.NLLLoss()\n",
    "    bs=outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3=id3x3.cuda()\n",
    "        id64x64=id64x64.cuda()\n",
    "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
    "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xE2VhMqqJhLK"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qR0dGkT3JjPG"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X111qYlXJmN8",
    "outputId": "aabe9685-11a9-4745-b402-44f75c721c8c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPeIpcIuJsrl"
   },
   "outputs": [],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZqHI8sTLJ14-"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ9s3RQUJ4Et"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
    "  for epoch in range(epochs): \n",
    "      pointnet.train()\n",
    "      running_loss = 0.0\n",
    "      for i, data in enumerate(train_loader, 0):\n",
    "          inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "          loss = pointnetloss(outputs, labels, m3x3, m64x64)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          # print statistics\n",
    "          running_loss += loss.item()\n",
    "          if i % 10 == 9:    # print every 10 mini-batches\n",
    "                  print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                  running_loss = 0.0\n",
    "\n",
    "      pointnet.eval()\n",
    "      correct = total = 0\n",
    "\n",
    "      # validation\n",
    "      if val_loader:\n",
    "          with torch.no_grad():\n",
    "              for data in val_loader:\n",
    "                  inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                  outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                  _, predicted = torch.max(outputs.data, 1)\n",
    "                  total += labels.size(0)\n",
    "                  correct += (predicted == labels).sum().item()\n",
    "          val_acc = 100. * correct / total\n",
    "          print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "      # save the model\n",
    "      if save:\n",
    "          torch.save(pointnet.state_dict(), \"save_\" + str(epoch) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-_S2ksvpKD8t",
    "outputId": "29fe3529-7b26-4280-a585-598eed98c057"
   },
   "outputs": [],
   "source": [
    "train(pointnet, train_loader, valid_loader, epochs=15, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoIdGv5cfrXt"
   },
   "source": [
    "# **Inference & Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIj_Mwn_fxkW"
   },
   "outputs": [],
   "source": [
    "# Load a validation dataset and a pre-trained model.\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)\n",
    "\n",
    "pointnet = PointNet()\n",
    "# GPU\n",
    "pointnet.load_state_dict(torch.load('save_14.pth'))\n",
    "\n",
    "# CPU\n",
    "#pointnet.load_state_dict(torch.load('save_14.pth', map_location=torch.device('cpu')))\n",
    "pointnet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWfumBjtg3Mg",
    "outputId": "e27fb5a5-86f1-428e-8311-1704ac750a42"
   },
   "outputs": [],
   "source": [
    "# Perform inference on a whole validation dataset.\n",
    "# N.B. Inference on a single point cloud does not work! Expected input shape is 64 (batch size)!\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(valid_loader):\n",
    "      print('Batch [%4d / %4d]' % (i+1, len(valid_loader)))\n",
    "                  \n",
    "      inputs, labels = data['pointcloud'].float(), data['category']\n",
    "      outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "      _, preds = torch.max(outputs.data, 1)\n",
    "      all_preds += list(preds.numpy())\n",
    "      all_labels += list(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1ZN3n9bkxr2",
    "outputId": "0f6e0d42-763b-4a34-81a5-e02677308c64"
   },
   "outputs": [],
   "source": [
    "# Visualize a single dataset element\n",
    "# N.B. DataLoaders are iterators through datasets!\n",
    "n_sample = 200\n",
    "print(\"Sample: \", n_sample)\n",
    "print(\"Pointcloud: \")\n",
    "print(valid_ds[n_sample]['pointcloud'])\n",
    "print(\"Label: \")\n",
    "print(list(classes.keys())[valid_ds[n_sample]['category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "gO-13Hc36s3P",
    "outputId": "80255fa7-ad09-4505-fdbc-786cfdef1907"
   },
   "outputs": [],
   "source": [
    "print(\"Predicted label: \", list(classes.keys())[all_preds[n_sample]])\n",
    "print(\"True label: \", list(classes.keys())[all_labels[n_sample]])\n",
    "pcshow(*valid_ds[n_sample]['pointcloud'].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8jUzgxRh2B3",
    "outputId": "087596c5-6ff0-4f50-b97a-32fa1b545085"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds);\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUv4xrAvh59R"
   },
   "outputs": [],
   "source": [
    "# Visualize confusion matrix:\n",
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "LV4RVSSsh8kw",
    "outputId": "66435591-758e-49a9-8651-c9c7468afb31"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "V6l-CBDciP7m",
    "outputId": "ceb7f56a-2545-4976-f047-11fc53be6cc4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "selene",
   "language": "python",
   "name": "selene"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
